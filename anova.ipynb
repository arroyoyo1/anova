{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.4.0"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30749,"isInternetEnabled":false,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# One-Way ANOVA without repeated measurements","metadata":{"_uuid":"6e03789b-3695-4e74-8743-8002fce8e3f5","_cell_guid":"ebfbd982-4eca-4e08-b42c-217ccac7465c","trusted":true,"collapsed":false,"_kg_hide-output":true,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### Suppose a study wants to check if there is a significant difference between the percentage of successful hits of baseball players in the Mexican league depending on the position in which they play. If there is a difference, we want to know which positions differ from the rest. The following table contains a sample of randomly selected players.","metadata":{"_uuid":"cca6ea5a-4ba1-4aa0-9561-b2849c051e35","_cell_guid":"f354195f-d2fc-459d-9a56-dceb80b637b8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"library(stats)    \nlibrary(car)       \nlibrary(ggplot2)    \nlibrary(multcomp)   \nlibrary(dplyr)  \nlibrary(nortest)\nlibrary(gridExtra)\nlibrary(lsr)\nlibrary(lmtest)\nlibrary(tidyr)\nlibrary(PMCMRplus)","metadata":{"_uuid":"5666e6c3-bf9f-4e4f-9969-e8a970c304e5","_cell_guid":"f398caba-d9ff-403f-a761-811b402a099c","trusted":true,"collapsed":false,"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"position <- c(\"OF\", \"IF\", \"IF\", \"OF\", \"IF\", \"IF\", \"OF\", \"OF\", \"IF\", \"IF\", \"OF\", \"OF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"OF\", \"IF\", \"OF\", \"IF\", \"OF\", \"IF\", \"OF\", \"IF\", \"DH\", \"IF\", \"IF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"OF\", \"IF\", \"OF\", \"OF\", \"IF\", \"IF\", \"OF\", \"OF\", \"IF\", \"OF\", \"OF\", \"OF\", \"IF\", \"DH\", \"OF\", \"OF\", \"OF\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"IF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"OF\", \"IF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"DH\", \"OF\", \"OF\", \"IF\", \"IF\", \"IF\", \"OF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"OF\", \"OF\", \"DH\", \"OF\", \"IF\", \"IF\", \"OF\", \"OF\", \"C\", \"IF\", \"OF\", \"OF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"OF\", \"C\", \"OF\", \"IF\", \"C\", \"OF\", \"IF\", \"DH\", \"C\", \"OF\", \"OF\", \"IF\", \"C\", \"IF\", \"IF\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"C\", \"IF\", \"OF\", \"OF\", \"IF\", \"OF\", \"IF\", \"OF\", \"DH\", \"C\", \"IF\", \"OF\", \"IF\", \"IF\", \"OF\", \"IF\", \"OF\", \"IF\", \"C\", \"IF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"OF\", \"OF\", \"OF\", \"IF\", \"IF\", \"C\", \"IF\", \"C\", \"C\", \"OF\", \"OF\", \"OF\", \"IF\", \"OF\", \"IF\", \"C\", \"DH\", \"DH\", \"C\", \"OF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"C\", \"IF\", \"OF\", \"DH\", \"IF\", \"IF\", \"IF\", \"OF\", \"OF\", \"C\", \"OF\", \"OF\", \"IF\", \"IF\", \"OF\", \"OF\", \"OF\", \"OF\", \"OF\", \"OF\", \"IF\", \"IF\", \"DH\", \"OF\", \"IF\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"IF\", \"C\", \"IF\", \"IF\", \"C\", \"IF\", \"OF\", \"IF\", \"DH\", \"C\", \"OF\", \"C\", \"IF\", \"IF\", \"OF\", \"C\", \"IF\", \"IF\", \"IF\", \"C\", \"C\", \"C\", \"OF\", \"OF\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"OF\", \"C\", \"IF\", \"IF\", \"OF\", \"C\", \"OF\", \"OF\", \"OF\", \"OF\", \"OF\", \"OF\", \"OF\", \"OF\", \"OF\", \"OF\", \"OF\", \"C\", \"IF\", \"DH\", \"IF\", \"C\", \"DH\", \"C\", \"IF\", \"C\", \"OF\", \"C\", \"C\", \"IF\", \"OF\", \"IF\", \"IF\", \"IF\", \"IF\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"OF\", \"OF\", \"IF\", \"OF\", \"OF\", \"IF\", \"IF\", \"IF\", \"OF\", \"C\", \"IF\", \"IF\", \"IF\", \"IF\", \"OF\", \"OF\", \"IF\", \"OF\", \"IF\", \"OF\", \"OF\", \"OF\", \"IF\", \"OF\", \"OF\", \"IF\", \"OF\", \"IF\", \"C\", \"IF\", \"IF\", \"C\", \"DH\", \"OF\", \"IF\", \"C\", \"C\", \"IF\", \"C\", \"IF\", \"OF\", \"C\", \"C\", \"OF\")\nhitting <- c(0.359, 0.34, 0.33, 0.341, 0.366, 0.333, 0.37, 0.331, 0.381, 0.332, 0.365, 0.345, 0.313, 0.325, 0.327, 0.337, 0.336, 0.291, 0.34, 0.31, 0.365, 0.356, 0.35, 0.39, 0.388, 0.345, 0.27, 0.306, 0.393, 0.331, 0.365, 0.369, 0.342, 0.329, 0.376, 0.414, 0.327, 0.354, 0.321, 0.37, 0.313, 0.341, 0.325, 0.312, 0.346, 0.34, 0.401, 0.372, 0.352, 0.354, 0.341, 0.365, 0.333, 0.378, 0.385, 0.287, 0.303, 0.334, 0.359, 0.352, 0.321, 0.323, 0.302, 0.349, 0.32, 0.356, 0.34, 0.393, 0.288, 0.339, 0.388, 0.283, 0.311, 0.401, 0.353, 0.42, 0.393, 0.347, 0.424, 0.378, 0.346, 0.355, 0.322, 0.341, 0.306, 0.329, 0.271, 0.32, 0.308, 0.322, 0.388, 0.351, 0.341, 0.31, 0.393, 0.411, 0.323, 0.37, 0.364, 0.321, 0.351, 0.329, 0.327, 0.402, 0.32, 0.353, 0.319, 0.319, 0.343, 0.288, 0.32, 0.338, 0.322, 0.303, 0.356, 0.303, 0.351, 0.325, 0.325, 0.361, 0.375, 0.341, 0.383, 0.328, 0.3, 0.277, 0.359, 0.358, 0.381, 0.324, 0.293, 0.324, 0.329, 0.294, 0.32, 0.361, 0.347, 0.317, 0.316, 0.342, 0.368, 0.319, 0.317, 0.302, 0.321, 0.336, 0.347, 0.279, 0.309, 0.358, 0.318, 0.342, 0.299, 0.332, 0.349, 0.387, 0.335, 0.358, 0.312, 0.307, 0.28, 0.344, 0.314, 0.24, 0.331, 0.357, 0.346, 0.351, 0.293, 0.308, 0.374, 0.362, 0.294, 0.314, 0.374, 0.315, 0.324, 0.382, 0.353, 0.305, 0.338, 0.366, 0.357, 0.326, 0.332, 0.323, 0.306, 0.31, 0.31, 0.333, 0.34, 0.4, 0.389, 0.308, 0.411, 0.278, 0.326, 0.335, 0.316, 0.371, 0.314, 0.384, 0.379, 0.32, 0.395, 0.347, 0.307, 0.326, 0.316, 0.341, 0.308, 0.327, 0.337, 0.36, 0.32, 0.372, 0.306, 0.305, 0.347, 0.281, 0.281, 0.296, 0.306, 0.343, 0.378, 0.393, 0.337, 0.327, 0.336, 0.32, 0.381, 0.306, 0.358, 0.311, 0.284, 0.364, 0.315, 0.342, 0.367, 0.307, 0.351, 0.372, 0.304, 0.296, 0.332, 0.312, 0.437, 0.295, 0.316, 0.298, 0.302, 0.342, 0.364, 0.304, 0.295, 0.305, 0.359, 0.335, 0.338, 0.341, 0.3, 0.378, 0.412, 0.273, 0.308, 0.309, 0.263, 0.291, 0.359, 0.352, 0.262, 0.274, 0.334, 0.343, 0.267, 0.321, 0.3, 0.327, 0.313, 0.316, 0.337, 0.268, 0.342, 0.292, 0.39, 0.332, 0.315, 0.298, 0.298, 0.331, 0.361, 0.272, 0.287, 0.34, 0.317, 0.327, 0.354, 0.317, 0.311, 0.174, 0.302, 0.302, 0.291, 0.29, 0.268, 0.352, 0.341, 0.265, 0.307, 0.36, 0.305, 0.254, 0.279, 0.321, 0.305, 0.35, 0.308, 0.326, 0.219, 0.23, 0.322, 0.405, 0.321, 0.291, 0.312, 0.357, 0.324)\n\ndf <- data.frame(position = position, hitting = hitting)\nhead(df,5)","metadata":{"_uuid":"13931e99-0381-4934-8ca9-c21cce89842f","_cell_guid":"7aab69e3-9263-4091-837a-89684e4f2788","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:08.895654Z","iopub.execute_input":"2024-12-25T19:25:08.934071Z","iopub.status.idle":"2024-12-25T19:25:08.966925Z","shell.execute_reply":"2024-12-25T19:25:08.965222Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.- Number of groups, observations per group and distribution of observations.","metadata":{"_uuid":"bfbd855b-0c3e-48df-b332-2cb24b1ee518","_cell_guid":"3f8567ce-06ed-41cc-be6b-c9381db083e9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### Counts the frequencies of each single value in the position column of the dataframe.","metadata":{"_uuid":"c95ba6ae-3427-447b-bca6-2f8a368c0e7b","_cell_guid":"a5baad03-ec1a-44b9-a0c9-a09f4eaaeace","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"table(df$position)","metadata":{"_uuid":"447eae5a-6932-4995-89ef-5c6465d1acaa","_cell_guid":"79f50347-cb8c-4e23-aa7e-70cfd8bb4db7","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:08.969491Z","iopub.execute_input":"2024-12-25T19:25:08.970847Z","iopub.status.idle":"2024-12-25T19:25:08.985768Z","shell.execute_reply":"2024-12-25T19:25:08.984071Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Calculates the mean and standard deviation of hitting by position","metadata":{"_uuid":"03b5b139-e87b-4b24-8a97-58d7077ff1b6","_cell_guid":"ff7fc7dc-30db-4532-b894-26869d76857e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"aggregate(hitting ~ position, data = df, FUN = mean)\naggregate(hitting ~ position, data = df, FUN = sd)","metadata":{"_uuid":"914ae993-3941-4667-a761-d3cf1f64aed9","_cell_guid":"445b9232-d4e8-4e2b-a0dd-c42f7cb0eec8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:08.988648Z","iopub.execute_input":"2024-12-25T19:25:08.990184Z","iopub.status.idle":"2024-12-25T19:25:09.027259Z","shell.execute_reply":"2024-12-25T19:25:09.025527Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Since the number of observations per group is not constant, it is an unbalanced model. It is important to take this into account when testing for normality and homoscedasticity conditions.\n\n#### The most useful graphical representation before performing an ANOVA is the Box-Plot model.","metadata":{"_uuid":"7801c199-5d7c-49cb-88ca-94e457a00ca9","_cell_guid":"ace6b155-4dd8-4c63-a16d-3d2af383fc7b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"ggplot(data = df, aes(x = position, y = hitting, color = position)) +\n    geom_boxplot() +\n    theme_minimal() +\n    labs(\n        title = \"Hitting distribution by position\", \n        x = \"Player's Position\",                  \n        y = \"Hitting Percentage\"                 \n    ) +\n    theme(\n        plot.title = element_text(hjust = 0.5, size = 16),  \n        axis.title.x = element_text(size = 12),             \n        axis.title.y = element_text(size = 12)     \n    )","metadata":{"_uuid":"d839d3ec-4d66-42bf-a80a-c2072663747d","_cell_guid":"f53ed014-469b-4d0a-8ae1-8e3775b41eb5","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:09.029906Z","iopub.execute_input":"2024-12-25T19:25:09.031300Z","iopub.status.idle":"2024-12-25T19:25:09.904910Z","shell.execute_reply":"2024-12-25T19:25:09.902966Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### The 4 groups seem to follow a symmetrical distribution. Some outliers are detected at the IF level. The size of the boxes is similar for all levels. The symmetry of the boxes indicates that the data at each position are approximately balanced around the median. It is likely that there are some players with exceptionally good or poor performance in the infielders group. These outliers could be distorting the overall picture of performance at that position and could be objects of study to identify reasons why these players are outside the typical range. The fact that the boxes have similar sizes in the different groups suggests that the variability of the slugging percentage is similar across positions so there is no indication of a lack of homoscedasticity.","metadata":{"_uuid":"054f75b6-1cad-4aba-806e-2b3e083dfbc0","_cell_guid":"59b7bad2-e2f8-4903-87fe-cee50ddc8ffd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 2.- Check conditions for an ANOVA.","metadata":{"_uuid":"7d30bf1e-8f02-4d37-99d5-6bca1a2f6346","_cell_guid":"9b7eabc6-77ec-41a1-94e6-baee22b162d5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### Independence: The total sample size is less than 10% of the population of all positions in the league. The groups (categorical variable) are independent of each other as they are randomly sampled from players across the league (not just from the same team).","metadata":{"_uuid":"90b83629-8c56-4fdf-8d4e-0edde158fe92","_cell_guid":"f7bc2134-c8c9-4cd6-9e45-3ae041bf46da","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### Normality: The quantitative variable should be normally distributed in each of the groups. The study of normality can be done graphically (qqplot) or with hypothesis testing.","metadata":{"_uuid":"69f21826-a15b-40d9-92f2-5ca6cd8eb7ac","_cell_guid":"e4d73f09-fa75-4161-9335-edadace6e7f1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"par(mfrow = c(2,2))\nqqnorm(df[df$position == \"C\",\"hitting\"], main = \"Catcher\")\nqqline(df[df$position == \"C\",\"hitting\"])\n\nqqnorm(df[df$position == \"DH\",\"hitting\"], main = \"Designated Hitter\")\nqqline(df[df$position == \"DH\",\"hitting\"])\n\nqqnorm(df[df$position == \"IF\",\"hitting\"], main = \"Infielder\")\nqqline(df[df$position == \"IF\",\"hitting\"])\n\nqqnorm(df[df$position == \"OF\",\"hitting\"], main = \"Outfielder\")\nqqline(df[df$position == \"OF\",\"hitting\"])","metadata":{"_uuid":"7923a273-e2ba-4538-a721-5a3e05c636b2","_cell_guid":"b58f031e-6154-4f61-a23c-5ec4367af516","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:09.907584Z","iopub.execute_input":"2024-12-25T19:25:09.909049Z","iopub.status.idle":"2024-12-25T19:25:10.048010Z","shell.execute_reply":"2024-12-25T19:25:10.046129Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"shapiro.test(df[df$position == \"DH\", \"hitting\"])\n\nshapiro.test(df[df$position == \"C\", \"hitting\"])\n\nlillie.test(df[df$position == \"IF\", \"hitting\"])\n\nlillie.test(df[df$position == \"OF\", \"hitting\"])","metadata":{"_uuid":"607e9325-6069-4ad3-a190-f1b5fcf6968d","_cell_guid":"5c7498c9-d9e5-4198-a902-0e87f665884b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:10.050567Z","iopub.execute_input":"2024-12-25T19:25:10.051893Z","iopub.status.idle":"2024-12-25T19:25:10.085313Z","shell.execute_reply":"2024-12-25T19:25:10.083635Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### The shapiro.test() function performs the Shapiro-Wilk normality test. It is applied to the “DH” and “C” groups, which are the small and medium samples. I used the lillie.test() function to perform the Kolmogorov-Smirnov test with Lilliefors correction. This test is applied to the “IF” and “OF” groups, which are larger samples. Considering a significance level of 0.05, all positions have a normal distribution by having p-values greater than the significance level.","metadata":{"_uuid":"7dc60a13-367a-4e29-8625-6b941decbb0b","_cell_guid":"63787a39-15a1-4015-8b23-4eab5d9b59a0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### Homoscedasticity: Since IF is at the limit to accept that it is normally distributed, Fisher's test and Bartlett's test are not recommended. Instead, it is better to use a median-based test such as the Fligner-Killeen test.n.","metadata":{"_uuid":"89334c81-6bf3-4d71-bd92-6a8b143844d5","_cell_guid":"24f57bd0-9629-4210-8b45-4313e46a663f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"fligner.test(hitting ~ position, df)\n\ndf$position <- as.factor(df$position)\nclass(df$position)\nleveneTest(hitting ~ position, df, center = \"median\")","metadata":{"_uuid":"fa84a50a-ab8d-4d21-8778-006c3f6952b3","_cell_guid":"d5f25069-a22f-43a6-854c-d0100d50bf86","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:10.087894Z","iopub.execute_input":"2024-12-25T19:25:10.089279Z","iopub.status.idle":"2024-12-25T19:25:10.129396Z","shell.execute_reply":"2024-12-25T19:25:10.127649Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3.- Performing the ANOVA","metadata":{"_uuid":"7e465b5c-cc3c-4c56-91d4-b9244f7242b1","_cell_guid":"a15c63d1-eaca-49e6-b6bf-581ed6e5d944","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"par(mfrow = c(2,2))\nanova <- aov(df$hitting ~ df$position)\nsummary(anova)\nplot(anova)\n\nf_crit <- qf(p = 0.05, df1 = 3, df2 = 323, lower.tail = FALSE)\nprint(paste(\"Critical Value of F at alpha = 0.05 with df = 3 (num),323(den) = \", f_crit))","metadata":{"_uuid":"b3edd2eb-397d-479c-96fa-3fa6827b7960","_cell_guid":"c7188288-6436-4c4b-a72b-9f6bcae7b8b3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:10.132068Z","iopub.execute_input":"2024-12-25T19:25:10.133708Z","iopub.status.idle":"2024-12-25T19:25:10.351067Z","shell.execute_reply":"2024-12-25T19:25:10.349152Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### 1. Residuals vs Fitted: This plot helps to check whether the erros have a random distribution. If that's the case (as in no patterns such as curves or clusters), the assumption of homoscedasticity and linearity in the model are reasonable.\n\n#### 2. Normal Q-Q: This plot compares the observed residuals with the expected residuals under a normal distribution. If the points are close to the straight line, the residuals follow a normal distribution. If the points deviate considerably, especially at the extremes, there may be problems with the normality of the residuals.\n\n#### Scale-Location: It shows the square root of the standardized residuals as a function of the fitted values. If the residuals have a constant variance, this plot should show a random distribution of the points. If there's a “shape” in the plot, it could indicate that the variance of the residuals is not constant. \n\n#### 4. Standardized residuals vs leverage: The points with high leverage are those that have extreme prediction values, so if a point has a large impact on the model, it could be distorting the results. Points that are outside the majority of the point group could be influential points that could affect the model fit. It is important to investigate these points to ensure that they are not unduly affecting the results.","metadata":{"_uuid":"727a9b84-eaf2-4e22-8b15-f24a429d8ea1","_cell_guid":"f017e709-c4be-4269-91fd-b2ac90660c45","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### Since the p-value is greater than 0.05 there is insufficient evidence to consider that at least one mean is different. The graphical representation of the residuals shows no lack of homoscedasticity (graph 1) and in the qqplot the residuals are distributed very close to the normal line (graph 2).","metadata":{"_uuid":"640b765b-dfb0-4c8a-95f2-ed9a2bc1ea44","_cell_guid":"4a7ec4a2-65eb-413a-948d-de5b44b9c92c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 4.- Calculating the effect size of an ANOVA","metadata":{"_uuid":"c77d36df-0123-4984-8d10-06edc9906246","_cell_guid":"25547d21-63d5-4976-b8cd-4aef205bfa9e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### The values needed to calculate η²  are obtained from the summary ANOVA","metadata":{"_uuid":"37bbe383-ca6e-44f6-a79f-74daaebc4ec4","_cell_guid":"8b49b0a0-7603-4c4c-8482-c2384ef5dcb5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"eta_squared <- 0.0076/(0.0076 + 0.4080)\nprint(paste(\"Eta Squared = \", eta_squared))","metadata":{"_uuid":"cf9ea3a3-9998-4976-9c94-77968472d944","_cell_guid":"6beb4770-8dfb-434e-98b4-5278eb854c20","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:10.353857Z","iopub.execute_input":"2024-12-25T19:25:10.355318Z","iopub.status.idle":"2024-12-25T19:25:10.374912Z","shell.execute_reply":"2024-12-25T19:25:10.372774Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### The obtained value of η² indicates that only 1.83% of the total variability in the hitting data can be explained by the position of the players.","metadata":{"_uuid":"92cbd76c-57c3-461c-b5f6-55079a9621c1","_cell_guid":"da14624b-253f-4e0e-8dd5-01362c48f42d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 5.- Multiple Comparisons","metadata":{"_uuid":"a806bebb-379c-408e-8696-e4723071ab5b","_cell_guid":"6eac178b-9a2f-43b0-b9ed-d5e1ad865a6c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### In this case the ANOVA was not significant so it doesn't make sense to make paired comparisons. However, for learning purposes I'll do it. Among the different methods of multiple comparisons and corrections, the two most recommended ones will be used: Holm's correction and TukeyHSD.","metadata":{"_uuid":"ee72e79e-a3d9-4c8c-9ae4-4de8139d2ad9","_cell_guid":"d3010b51-860d-46be-af13-08a009af9355","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"pairwise.t.test(x = df$hitting, g = df$position, p.adjust.method = \"holm\",\n                pool.sd = TRUE, paired = FALSE, alternative = \"two.sided\")\n\nTukeyHSD(anova)\nplot(TukeyHSD(anova))","metadata":{"_uuid":"95ab60a0-f324-400f-9e28-c8ad5a79c857","_cell_guid":"e4913c08-4d2a-46d6-80d3-7dc20bb47739","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:10.378445Z","iopub.execute_input":"2024-12-25T19:25:10.380780Z","iopub.status.idle":"2024-12-25T19:25:10.495944Z","shell.execute_reply":"2024-12-25T19:25:10.494040Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.- Conclusion","metadata":{"_uuid":"415f4dd4-f499-4af2-b63c-c0f844e33530","_cell_guid":"71445ca4-58ee-48ec-94a6-8044c7d2c253","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### With a p-value of 0.115, an F-test statistic of 1.994, critical value of 2.6326 at the significance level of 0.05 and 3, 323 degrees of freedom and eta squared of 0.1829, it can be concluded that there is insufficient evidence to claim that hitting performance differ significantly between player positions and that any differences observed between the groups are very small and could be the product of chance","metadata":{"_uuid":"b4196e62-4841-4ffe-8d5a-a92b57c6b5c4","_cell_guid":"1a87c8df-7752-4eba-81cf-6af14bb86d4d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"# Two-Way ANOVA without repeated measurements","metadata":{"_uuid":"4c8fec95-b21b-4c2f-a562-975f12f35ed5","_cell_guid":"0a466cd3-8571-4a7a-84e0-fdff4080f50f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### A building materials company wants to study the influence of thickness and type of tempering on the ultimate strength of steel sheets. For this purpose, they measure the stress to rupture (response variable) for two types of tempering (slow and fast) and three sheet thicknesses (8 mm, 16 mm and 24 mm).","metadata":{"_uuid":"61edf48d-96fc-43cd-a701-d0cee10e4ddb","_cell_guid":"70cf72d4-ddf5-4cfb-80fe-dbbc56de70dc","trusted":true,"collapsed":false,"_kg_hide-output":true,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"resistance <- c(15.29, 15.89, 16.02, 16.56, 15.46, 16.91, 16.99, 17.27, 16.85,\n                 16.35, 17.23, 17.81, 17.74, 18.02, 18.37, 12.07, 12.42, 12.73,\n                 13.02, 12.05, 12.92, 13.01, 12.21, 13.49, 14.01, 13.30, 12.82,\n                 12.49, 13.55, 14.53)\ntempering <- c(rep(c(\"fast\", \"slow\"), c(15,15)))\nthickness <- rep(c(8, 16, 24), each = 5, times = 2)\ndf <- data.frame(tempering = tempering, thickness = as.factor(thickness),\n                    resistance = resistance)\nhead(df,5)","metadata":{"_uuid":"4d213d51-a3ba-45ef-8477-7d0b5d80cf2a","_cell_guid":"4fafef44-c975-4765-b1fb-32796b01ea08","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:10.498644Z","iopub.execute_input":"2024-12-25T19:25:10.500066Z","iopub.status.idle":"2024-12-25T19:25:10.536689Z","shell.execute_reply":"2024-12-25T19:25:10.534563Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.- Analyzing the distribution of the data.","metadata":{"_uuid":"8e7f8123-cb95-4e10-b13e-bafa0ea5c63a","_cell_guid":"f19bcb08-b87b-4769-bfbf-5cc650ac4f96","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### First, I generate box-plots to identify possible significant differences, asymmetries, outliers and homogeneity of variance between the different levels. Also show the mean and variance of each group.","metadata":{"_uuid":"8d0d61c7-bfaf-41d7-a7f4-65655152d743","_cell_guid":"f06db25c-2940-426d-b9ce-6f3f94e2cdcb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"p1 <- ggplot(data = df, aes(x = tempering, y = resistance)) + \n      geom_boxplot() + theme_bw()\np2 <- ggplot(data = df, aes(x = thickness, y = resistance)) +\n      geom_boxplot() + theme_bw()\np3 <- ggplot(data = df, aes(x = tempering, y = resistance, colour = thickness)) +\n      geom_boxplot() + theme_bw()\n\nplot(p1)\nplot(p2)\nplot(p3)","metadata":{"_uuid":"523285f9-821e-4f5f-a6aa-9e23200234c2","_cell_guid":"2de8c54b-0703-45fd-b4e5-0e633ddf8e51","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:10.540006Z","iopub.execute_input":"2024-12-25T19:25:10.542250Z","iopub.status.idle":"2024-12-25T19:25:11.686049Z","shell.execute_reply":"2024-12-25T19:25:11.683291Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with(data = df,expr = tapply(resistance, tempering, mean))\nwith(data = df,expr = tapply(resistance, tempering, sd))\nwith(data = df,expr = tapply(resistance, thickness, mean))\nwith(data = df,expr = tapply(resistance, thickness, sd))\nwith(data = df,expr = tapply(resistance, list(tempering,thickness), mean))\nwith(data = df,expr = tapply(resistance, list(tempering,thickness), sd))","metadata":{"_uuid":"c4a1e87b-be73-4e49-a7b6-731a6a0ceee2","_cell_guid":"01e6a8fb-862a-4a53-9ca4-ab4ffea8616a","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:11.690127Z","iopub.execute_input":"2024-12-25T19:25:11.691486Z","iopub.status.idle":"2024-12-25T19:25:11.745295Z","shell.execute_reply":"2024-12-25T19:25:11.742980Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### From the graphical representation and the calculation of the averages, it can be intuited that there is a difference in the resistance achieved depending on the type of tempering. The resistance seems to increase as the thickness of the sheet increases, although it is not clear that the difference in the means are significant. The distribution of observations at each level appears symmetrical with no outliers. It seems that the necessary conditions for an ANOVA are satisfied, although they will have to be confirmed by analyzing the residuals.","metadata":{"_uuid":"c16a1c09-12d9-455a-a529-f7773d1809f0","_cell_guid":"e7947a58-b1ac-4d67-917e-414ecb97e52f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 2.- Interaction Plots","metadata":{"_uuid":"08cbcd84-4d60-43a2-bf31-7ebd91e6f52f","_cell_guid":"2f7afbb0-8314-4f15-b7ce-8c86c360df4c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### It is also possible to identify possible interactions of the two factors graphically using interaction plots. If the lines describing the data for each of the levels are parallel, it means that the behavior is similar regardless of the level of the factor, meaning there is no interaction.","metadata":{"_uuid":"a21fcfa6-cf30-4e09-a819-6effccda6c76","_cell_guid":"e7c8e9d0-2bfe-4f27-a239-535ebc32a1d0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"ggplot(data = df, aes(x = tempering, y = resistance, colour = thickness,\n                         group = thickness)) +\n    stat_summary(fun = mean, geom = \"point\") +\n    stat_summary(fun = mean, geom = \"line\") +\n    theme_minimal()","metadata":{"_uuid":"44f47084-c794-4472-8865-27937b7a7863","_cell_guid":"e34cbea1-819a-48f6-b30e-7183f97ebda3","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:11.748339Z","iopub.execute_input":"2024-12-25T19:25:11.749741Z","iopub.status.idle":"2024-12-25T19:25:12.075608Z","shell.execute_reply":"2024-12-25T19:25:12.073711Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ggplot(data = df, aes(x = thickness, y = resistance, colour = tempering,\n                         group = tempering)) +\n    stat_summary(fun = mean, geom = \"point\") +\n    stat_summary(fun = mean, geom = \"line\") +\n    theme_bw()","metadata":{"_uuid":"1c51954a-4cbd-43e1-95a5-8c347ae8175c","_cell_guid":"e742c8fc-3ad8-4356-9106-e450cfada77f","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.078311Z","iopub.execute_input":"2024-12-25T19:25:12.079694Z","iopub.status.idle":"2024-12-25T19:25:12.433436Z","shell.execute_reply":"2024-12-25T19:25:12.431566Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### The interaction plots seem to indicate (in the absence of p-values) that the increase in resistance between the two types of tempering is proportional for the three thicknesses. When plotting the resistance as a function of thickness for the two types of tempering, a certain deviation seems to be observed for the 24 mm sheets. This slight deviation could be due to simple variability or because there is an interaction between the thickness and tempering variables, which must be confirmed by ANOVA, so that is what I am going to do next up.","metadata":{"_uuid":"46fd69b3-ec88-45fe-b4e7-7ae1ec564f15","_cell_guid":"f8d1afc5-df4d-474a-aac5-b254f41ff2eb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 3.- Performing the ANOVA","metadata":{"_uuid":"d7b20aea-010b-4c9c-9bae-c2ff6dede40e","_cell_guid":"4d8006de-edef-49c3-973a-c78412686a7b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"anova <- aov(resistance ~ tempering * thickness, data = df)\nsummary(anova)","metadata":{"_uuid":"a60bdf46-4a90-45af-ad15-b8d0cbc6de45","_cell_guid":"1a388d1c-9383-4cae-ba81-ba2d97f52500","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.436007Z","iopub.execute_input":"2024-12-25T19:25:12.437422Z","iopub.status.idle":"2024-12-25T19:25:12.457416Z","shell.execute_reply":"2024-12-25T19:25:12.455652Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Also I am going to calculate η²","metadata":{"_uuid":"084e492b-73ec-4832-9c96-189f626a8f15","_cell_guid":"97d8a81b-6d2c-46d7-ab32-a63d3979d24b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"etaSquared(anova)","metadata":{"_uuid":"35101bd7-915b-46b2-8365-0dc6bda19a2f","_cell_guid":"76b1ec4b-9bf2-4f2c-9115-1d9cf7f7a41c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.459943Z","iopub.execute_input":"2024-12-25T19:25:12.461294Z","iopub.status.idle":"2024-12-25T19:25:12.492841Z","shell.execute_reply":"2024-12-25T19:25:12.491103Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### The analysis of variance confirms that there is a significant influence on sheet resistance by both factors with effect sizes η² llarge and medium(tempering and thickness respectively), but there is no significant interaction between them.","metadata":{"_uuid":"29364b87-3e3c-4358-b98d-a2a2d77cd8b5","_cell_guid":"95472393-d195-488e-bdc9-abea3ecb89ad","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 4.- Check conditions for an ANOVA","metadata":{"_uuid":"d3d7de52-a8ec-4a48-b3c5-e636a6a05e2b","_cell_guid":"4fbc51ed-1ebd-421c-9150-61805ed03377","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### In order to validate the ANOVA results, it is necessary to verify that the conditions of an ANOVA are satisfied.","metadata":{"_uuid":"75b97ae2-1d87-4ed6-8eb6-129f4ed0fb1e","_cell_guid":"38fb715d-b300-45d1-a03e-8bf564638c66","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"par(mfrow = c(2,2))\nplot(anova)","metadata":{"_uuid":"6a4ce1a6-5293-44af-a1ad-cea5713fb25e","_cell_guid":"5b096ead-9287-41f1-8666-249e8ad03436","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.495426Z","iopub.execute_input":"2024-12-25T19:25:12.496843Z","iopub.status.idle":"2024-12-25T19:25:12.615234Z","shell.execute_reply":"2024-12-25T19:25:12.613048Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Independence: Given that there is a random scatter of the points around the horizontal line at zero (graph 1), with no form of any apparent pattern, the residuals are independent.","metadata":{"_uuid":"36e16133-f094-4978-a909-118ff79abfa5","_cell_guid":"48a679eb-a37e-4c54-8cda-e641bb0a828b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"by(df$resistance, list(df$tempering, df$thickness), function(x) shapiro.test(x)$p.value)","metadata":{"_uuid":"a65ce8e6-1cb0-4ed9-844f-38f5ef4f458e","_cell_guid":"0173ecf5-f329-48dc-823e-bc182bdb8c30","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.618043Z","iopub.execute_input":"2024-12-25T19:25:12.619541Z","iopub.status.idle":"2024-12-25T19:25:12.637768Z","shell.execute_reply":"2024-12-25T19:25:12.636068Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Normality:  Looking at graph 2, we could have some doubts (particularly because there are observations that do not fit so well to the line in the tails), so by performing the Shapiro-Wilk test to each combination of categories of both factors, I can confirm with the p-value that they are normally distributed.","metadata":{"_uuid":"dc29bf35-189a-4625-bb2d-7ab561d827fa","_cell_guid":"d8e88a1a-52ef-4eb7-9abf-0eb02b12fbac","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"bptest(anova)","metadata":{"_uuid":"a8157c01-0591-47a7-8cfa-fbe800f3f1c3","_cell_guid":"74b96349-add3-4c50-a937-acae092fd8a2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.640454Z","iopub.execute_input":"2024-12-25T19:25:12.641929Z","iopub.status.idle":"2024-12-25T19:25:12.658740Z","shell.execute_reply":"2024-12-25T19:25:12.656922Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Homoscedasticity: Looking at graph 1, the residuals appear to be randomly distributed with no clear pattern, which gives indications of homoscedasticity. But looking at graph 3, although the dispersion of the points appears relatively uniform, there are some areas where the points are more clustered. The red line does not appear to have a clear trend, but its curved shape suggests that there may be slight indications of heteroscedasticity, so to confirm, I will do the Breusch-Pagan test (the test assesses whether the residuals are systematically related to the fitted values of the model or to the explanatory variables) and since the p-value is larger than 0.05, we can confirm the homoscedasticity assumption","metadata":{"_uuid":"fc28ac52-43ac-4b46-b078-a55f615397c5","_cell_guid":"649550ca-aa45-45c0-bea5-07e575901f94","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 5.- Conclusion","metadata":{"_uuid":"f6a43ef2-3e54-43ec-9ee0-cbda0e9a2af8","_cell_guid":"7958e870-08bf-4fb7-aac4-8d7223a97ebd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### The two-way ANOVA results indicate significant main effects of both tempering and thickness on the dependent variable. Tempering shows a highly significant effect (F(1, 24) = 380.082, p < 0.001), so does thickness (F(2, 24) = 17.563, p < 0.001). However, the interaction between tempering and thickness is not statistically significant (F(2, 24) = 2.705, p = 0.087). This suggests that while both tempering and thickness independently influence the outcome, their combined effect does not significantly differ from what would be expected based on their individual effects.","metadata":{"_uuid":"89ea2498-0238-4892-a23b-0d547b45d672","_cell_guid":"2ebd81e6-e4f6-42ae-b138-2bd8a1f73d8e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"# ANOVA with repeated measurements","metadata":{"_uuid":"7f6f0ea4-fd80-4d71-8b09-0c553afd92a9","_cell_guid":"4eaaad2c-de1a-4f92-bcd5-2eba7aa18738","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### Suppose a study in which we want to check whether the price of groceries varies between 4 different supermarket chains. For this purpose, a series of daily shopping items are selected and their value is recorded in each of the supermarkets. Is there evidence that the average purchase price is different depending on the supermarket? (These are different measurements on the same item and are therefore paired data).","metadata":{"_uuid":"42eb2850-86e1-44c2-ab82-c5d6bf281af3","_cell_guid":"5e750145-7952-4d95-b9de-2b83a483c4da","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"item <- c(\"lettuce\", \"potatoes\", \"milk\", \"eggs\", \"bread\", \"cereal\", \"ground.beef\",\n              \"tomato.soup\", \"laundry.detergent\", \"aspirin\")\nWalmart <- c(1.755, 2.655, 2.235, 0.975, 2.370, 4.695, 3.135, 0.930, 8.235, 6.690)\nTarget <- c(1.78, 1.98, 1.69, 0.99, 1.70, 3.15, 1.88, 0.65, 5.99, 4.84)\nCostco <- c(1.29, 1.99, 1.79, 0.69, 1.89, 2.99, 2.09, 0.65, 5.99, 4.99)\nHaggen <- c(1.29, 1.99, 1.59, 1.09, 1.89, 3.09, 2.49, 0.69, 6.99, 5.15)\n\ndf <- data.frame(item, Walmart, Target, Costco, Haggen)\nhead(df,5)","metadata":{"_uuid":"bb7958a4-ae1d-4b91-b8f0-2448fdb2c796","_cell_guid":"0862983b-666f-4f97-b39a-ac0004c3bed1","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.661467Z","iopub.execute_input":"2024-12-25T19:25:12.662940Z","iopub.status.idle":"2024-12-25T19:25:12.697351Z","shell.execute_reply":"2024-12-25T19:25:12.695569Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### In order to visualize the data with ggplot2 and perform the initial exploration, the format is changed from “wide table” to “long table” with one column per variable.","metadata":{"_uuid":"8cb7879c-97dd-437b-9f2b-c75a5c50ba56","_cell_guid":"8141d5bd-508e-432c-bbde-9b17a6814f06","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"df_long <- gather(data = df, key = \"Supermarket\", value = \"Price\", 2:5)\nhead(df_long, 5)","metadata":{"_uuid":"457d1760-d3e7-4a1f-83cb-33f6ab65fc73","_cell_guid":"486a47b2-defd-446f-8706-4b793d4a9720","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.700010Z","iopub.execute_input":"2024-12-25T19:25:12.701467Z","iopub.status.idle":"2024-12-25T19:25:12.731941Z","shell.execute_reply":"2024-12-25T19:25:12.730180Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 1.- Analyzing the distribution of the data.","metadata":{"_uuid":"183ceb30-67fe-44ca-b262-c36a4194b1ed","_cell_guid":"ba274bed-12aa-450c-b25f-b716063181d9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"#### It is advisable to calculate the total price of each of the groups, as well as a graphical representation to get an idea of which could differ significantly","metadata":{"_uuid":"24b4f42d-8abf-4fe7-bfec-907c55cc71e7","_cell_guid":"a5790305-9e95-444c-bddc-2cb7b089a7d5","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"with(data = df_long,expr = tapply(Price, Supermarket, mean))\nwith(data = df_long,expr = tapply(Price, Supermarket, sd))","metadata":{"_uuid":"44c868f2-db25-4340-8266-1d7b3fc9c2c6","_cell_guid":"8b5822b0-5e89-4562-b7f9-5fdb73b6431e","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.734568Z","iopub.execute_input":"2024-12-25T19:25:12.736015Z","iopub.status.idle":"2024-12-25T19:25:12.756716Z","shell.execute_reply":"2024-12-25T19:25:12.754913Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ggplot(data = df_long, aes(x = Supermarket, y = Price, colour = Supermarket)) +\n  geom_boxplot() +\n  theme_minimal() +\n  theme(legend.position = \"none\")","metadata":{"_uuid":"8b27ffbe-e3e6-4bb4-b900-cbf44de36b70","_cell_guid":"27f0a08a-1392-4750-aa7c-1243629938a0","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:25:12.759409Z","iopub.execute_input":"2024-12-25T19:25:12.760853Z","iopub.status.idle":"2024-12-25T19:25:13.037100Z","shell.execute_reply":"2024-12-25T19:25:13.035315Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### The preliminary interpretation is that Walmart tends to have higher prices on average but with a wider variation, while Target offers more consistent and lower prices. Haggen appears to have a diverse price range, and Costco has a narrow, low-cost range with a few exceptions. Costco, Haggen, and Walmart show some outliers, representing items priced significantly higher than the rest of their data.","metadata":{"_uuid":"ca27789c-04f8-4b11-9599-30965464d072","_cell_guid":"3287eb6b-5b20-450c-a2f6-d988d7063d1e","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 2.- Check conditions","metadata":{"_uuid":"2c7c8f6e-7e58-4d57-bfdb-18eb7492cb0a","_cell_guid":"731fc883-4d18-4f61-aaef-66b54c84069b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"shapiro_results <- df_long %>%\n  group_by(Supermarket) %>%\n  summarize(p_value = shapiro.test(Price)$p.value)\n\nprint(shapiro_results)","metadata":{"_uuid":"27cfbe92-837f-4054-a9f4-c94fe7f28a74","_cell_guid":"d9a92cde-1792-4e98-a1c8-e72192b321ad","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:35:39.324794Z","iopub.execute_input":"2024-12-25T19:35:39.326409Z","iopub.status.idle":"2024-12-25T19:35:39.358164Z","shell.execute_reply":"2024-12-25T19:35:39.356514Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### Normality: Normality cannot be assumed for all supermarkets, so the normality assumption is violated, therefore it would be better to try with a non-parametric alternative.","metadata":{"_uuid":"293c8271-f07a-496c-b0cd-3b2ddf96b81d","_cell_guid":"227a0af3-f341-4afe-94f2-a621275a04bd","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"## 3.- Performing the ANOVA","metadata":{"_uuid":"3dba5ed7-e8f5-4ed3-97a9-ebe561e53b58","_cell_guid":"9bb743bd-c563-457d-ae8f-85834def5a50","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"friedman_result <- friedman.test(Price ~ Supermarket | item, data = df_long)\nprint(friedman_result)","metadata":{"_uuid":"a93b8094-0af9-4cf1-b6bf-1c0fe56cf2eb","_cell_guid":"58faad42-910b-494b-8fb0-fa11055ed4a8","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-12-25T19:39:49.737483Z","iopub.execute_input":"2024-12-25T19:39:49.739080Z","iopub.status.idle":"2024-12-25T19:39:49.758846Z","shell.execute_reply":"2024-12-25T19:39:49.757200Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### The p-value of 0.002834 is less than the significance level of 0.05 so I reject the null hypothesis and it can be said that there is sufficient evidence to affirm that there are significant differences in prices among supermarkets.","metadata":{"_uuid":"7f6255ee-10e3-470a-b93c-2c9658497581","_cell_guid":"ff04fe7e-588f-4b7a-bc98-2970364a7cb2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}}]}